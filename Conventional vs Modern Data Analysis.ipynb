{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODERN DATA ANALYTIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required libraries, including PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to load data: 0.30864715576171875 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "spark = SparkSession.builder.appName(\"AirQualityAnalytics\").getOrCreate()\n",
    "data = spark.read.csv('PRSA_data_2010.1.1-2014.12.31.csv', header=True, inferSchema=True)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time_loading = end_time - start_time\n",
    "print(f\"Time taken to load data: {elapsed_time_loading} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Spark session to enable the usage of Spark functionalities.\n",
    "Read the CSV file into a Spark DataFrame.\n",
    "Record the time elapsed to load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|min(pm2.5)|max(pm2.5)|\n",
      "+----------+----------+\n",
      "|         0|        NA|\n",
      "+----------+----------+\n",
      "\n",
      "+---+----+-----+---+----+-----+----+----+------+----+-----+---+---+\n",
      "| No|year|month|day|hour|pm2.5|DEWP|TEMP|  PRES|cbwd|  Iws| Is| Ir|\n",
      "+---+----+-----+---+----+-----+----+----+------+----+-----+---+---+\n",
      "| 25|2010|    1|  2|   0|  129| -16|-4.0|1020.0|  SE| 1.79|  0|  0|\n",
      "| 26|2010|    1|  2|   1|  148| -15|-4.0|1020.0|  SE| 2.68|  0|  0|\n",
      "| 27|2010|    1|  2|   2|  159| -11|-5.0|1021.0|  SE| 3.57|  0|  0|\n",
      "| 28|2010|    1|  2|   3|  181|  -7|-5.0|1022.0|  SE| 5.36|  1|  0|\n",
      "| 29|2010|    1|  2|   4|  138|  -7|-5.0|1022.0|  SE| 6.25|  2|  0|\n",
      "| 30|2010|    1|  2|   5|  109|  -7|-6.0|1022.0|  SE| 7.14|  3|  0|\n",
      "| 31|2010|    1|  2|   6|  105|  -7|-6.0|1023.0|  SE| 8.93|  4|  0|\n",
      "| 32|2010|    1|  2|   7|  124|  -7|-5.0|1024.0|  SE|10.72|  0|  0|\n",
      "| 33|2010|    1|  2|   8|  120|  -8|-6.0|1024.0|  SE|12.51|  0|  0|\n",
      "| 34|2010|    1|  2|   9|  132|  -7|-5.0|1025.0|  SE| 14.3|  0|  0|\n",
      "| 35|2010|    1|  2|  10|  140|  -7|-5.0|1026.0|  SE|17.43|  1|  0|\n",
      "| 36|2010|    1|  2|  11|  152|  -8|-5.0|1026.0|  SE|20.56|  0|  0|\n",
      "| 37|2010|    1|  2|  12|  148|  -8|-5.0|1026.0|  SE|23.69|  0|  0|\n",
      "| 38|2010|    1|  2|  13|  164|  -8|-5.0|1025.0|  SE|27.71|  0|  0|\n",
      "| 39|2010|    1|  2|  14|  158|  -9|-5.0|1025.0|  SE|31.73|  0|  0|\n",
      "| 40|2010|    1|  2|  15|  154|  -9|-5.0|1025.0|  SE|35.75|  0|  0|\n",
      "| 41|2010|    1|  2|  16|  159|  -9|-5.0|1026.0|  SE|37.54|  0|  0|\n",
      "| 42|2010|    1|  2|  17|  164|  -8|-5.0|1027.0|  SE|39.33|  0|  0|\n",
      "| 43|2010|    1|  2|  18|  170|  -8|-5.0|1027.0|  SE|42.46|  0|  0|\n",
      "| 44|2010|    1|  2|  19|  149|  -8|-5.0|1028.0|  SE|44.25|  0|  0|\n",
      "+---+----+-----+---+----+-----+----+----+------+----+-----+---+---+\n",
      "only showing top 20 rows\n",
      "\n",
      "Time taken for operations: 0.43802499771118164 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "data.selectExpr(\"min(`pm2.5`)\", \"max(`pm2.5`)\").show()\n",
    "data_cleaned = data.filter(col(\"`pm2.5`\") != 'NA')\n",
    "data_cleaned.show()\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken for operations: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the data range of pm2.5. Rows with 'NA' values in pm2.5 are cleaned with deletion methods. The resulting DataFrame data_cleaned will not contain those rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-----+---+----+-----+----+----+------+----+-----+---+---+--------------------+\n",
      "| No|year|month|day|hour|pm2.5|DEWP|TEMP|  PRES|cbwd|  Iws| Is| Ir|           timestamp|\n",
      "+---+----+-----+---+----+-----+----+----+------+----+-----+---+---+--------------------+\n",
      "| 25|2010|    1|  2|   0|  129| -16|-4.0|1020.0|  SE| 1.79|  0|  0|2010-01-02 00:00:...|\n",
      "| 26|2010|    1|  2|   1|  148| -15|-4.0|1020.0|  SE| 2.68|  0|  0|2010-01-02 01:00:...|\n",
      "| 27|2010|    1|  2|   2|  159| -11|-5.0|1021.0|  SE| 3.57|  0|  0|2010-01-02 02:00:...|\n",
      "| 28|2010|    1|  2|   3|  181|  -7|-5.0|1022.0|  SE| 5.36|  1|  0|2010-01-02 03:00:...|\n",
      "| 29|2010|    1|  2|   4|  138|  -7|-5.0|1022.0|  SE| 6.25|  2|  0|2010-01-02 04:00:...|\n",
      "| 30|2010|    1|  2|   5|  109|  -7|-6.0|1022.0|  SE| 7.14|  3|  0|2010-01-02 05:00:...|\n",
      "| 31|2010|    1|  2|   6|  105|  -7|-6.0|1023.0|  SE| 8.93|  4|  0|2010-01-02 06:00:...|\n",
      "| 32|2010|    1|  2|   7|  124|  -7|-5.0|1024.0|  SE|10.72|  0|  0|2010-01-02 07:00:...|\n",
      "| 33|2010|    1|  2|   8|  120|  -8|-6.0|1024.0|  SE|12.51|  0|  0|2010-01-02 08:00:...|\n",
      "| 34|2010|    1|  2|   9|  132|  -7|-5.0|1025.0|  SE| 14.3|  0|  0|2010-01-02 09:00:...|\n",
      "| 35|2010|    1|  2|  10|  140|  -7|-5.0|1026.0|  SE|17.43|  1|  0|2010-01-02 10:00:...|\n",
      "| 36|2010|    1|  2|  11|  152|  -8|-5.0|1026.0|  SE|20.56|  0|  0|2010-01-02 11:00:...|\n",
      "| 37|2010|    1|  2|  12|  148|  -8|-5.0|1026.0|  SE|23.69|  0|  0|2010-01-02 12:00:...|\n",
      "| 38|2010|    1|  2|  13|  164|  -8|-5.0|1025.0|  SE|27.71|  0|  0|2010-01-02 13:00:...|\n",
      "| 39|2010|    1|  2|  14|  158|  -9|-5.0|1025.0|  SE|31.73|  0|  0|2010-01-02 14:00:...|\n",
      "| 40|2010|    1|  2|  15|  154|  -9|-5.0|1025.0|  SE|35.75|  0|  0|2010-01-02 15:00:...|\n",
      "| 41|2010|    1|  2|  16|  159|  -9|-5.0|1026.0|  SE|37.54|  0|  0|2010-01-02 16:00:...|\n",
      "| 42|2010|    1|  2|  17|  164|  -8|-5.0|1027.0|  SE|39.33|  0|  0|2010-01-02 17:00:...|\n",
      "| 43|2010|    1|  2|  18|  170|  -8|-5.0|1027.0|  SE|42.46|  0|  0|2010-01-02 18:00:...|\n",
      "| 44|2010|    1|  2|  19|  149|  -8|-5.0|1028.0|  SE|44.25|  0|  0|2010-01-02 19:00:...|\n",
      "+---+----+-----+---+----+-----+----+----+------+----+-----+---+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Time taken for timestamp operation: 0.15811824798583984 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "from pyspark.sql.functions import concat, lit, col, lpad\n",
    "data = data_cleaned.withColumn(\n",
    "    \"timestamp\",\n",
    "    concat(\n",
    "        col(\"`year`\"), lit(\"-\"),\n",
    "        lpad(col(\"`month`\"), 2, \"0\"), lit(\"-\"),\n",
    "        lpad(col(\"`day`\"), 2, \"0\"), lit(\" \"),\n",
    "        lpad(col(\"`hour`\"), 2, \"0\"), lit(\":00:00:000\")\n",
    "    )\n",
    ")\n",
    "data.show()\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken for timestamp operation: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|           timestamp|avg(`pm2.5`)|\n",
      "+--------------------+------------+\n",
      "|2010-01-15 01:00:...|        37.0|\n",
      "|2010-02-03 09:00:...|       120.0|\n",
      "|2010-02-03 14:00:...|        17.0|\n",
      "|2010-02-13 08:00:...|        24.0|\n",
      "|2010-02-27 00:00:...|        38.0|\n",
      "|2010-03-14 10:00:...|        90.0|\n",
      "|2010-03-17 04:00:...|        41.0|\n",
      "|2010-03-26 06:00:...|        57.0|\n",
      "|2010-04-10 20:00:...|        56.0|\n",
      "|2010-04-17 19:00:...|       134.0|\n",
      "|2010-04-24 13:00:...|       111.0|\n",
      "|2010-05-03 22:00:...|       150.0|\n",
      "|2010-05-04 15:00:...|       104.0|\n",
      "|2010-05-05 02:00:...|       158.0|\n",
      "|2010-05-10 21:00:...|        20.0|\n",
      "|2010-05-18 16:00:...|        54.0|\n",
      "|2010-05-20 11:00:...|        53.0|\n",
      "|2010-05-25 08:00:...|        29.0|\n",
      "|2010-06-15 07:00:...|       196.0|\n",
      "|2010-06-21 06:00:...|        48.0|\n",
      "+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Time taken for aggregation operation: 0.48117852210998535 seconds\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "start_time = time.time()\n",
    "data = data.withColumn(\"`pm2.5`\", col(\"`pm2.5`\").cast(FloatType()))\n",
    "aggregated_data = data.groupBy(\"`timestamp`\").agg(avg(\"`pm2.5`\"))\n",
    "aggregated_data.show()\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken for aggregation operation: {elapsed_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum PM2.5 value on entire dataset: 994\n",
      "Time taken for analytics on entire dataset: 0.23000597953796387 seconds\n"
     ]
    }
   ],
   "source": [
    "# Start measuring time for analytics on entire dataset\n",
    "start_time_full_analytics = time.time()\n",
    "max_pm25_full = data.agg({\"`pm2.5`\": \"max\"}).collect()[0][0]\n",
    "end_time_full_analytics = time.time()\n",
    "elapsed_time_full_analytics = end_time_full_analytics - start_time_full_analytics\n",
    "\n",
    "print(f\"\\nMaximum PM2.5 value on entire dataset: {max_pm25_full}\")\n",
    "print(f\"Time taken for analytics on entire dataset: {elapsed_time_full_analytics} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum PM2.5 value on subset: 99\n",
      "Time taken for analytics on subset: 0.22312188148498535 seconds\n"
     ]
    }
   ],
   "source": [
    "# Subset of data for demonstration\n",
    "subset_data = data.sample(fraction=0.1, seed=42)\n",
    "start_time_subset_analytics = time.time()\n",
    "max_pm25_subset = subset_data.agg({\"`pm2.5`\": \"max\"}).collect()[0][0]\n",
    "end_time_subset_analytics = time.time()\n",
    "elapsed_time_subset_analytics = end_time_subset_analytics - start_time_subset_analytics\n",
    "\n",
    "print(f\"Maximum PM2.5 value on subset: {max_pm25_subset}\")\n",
    "print(f\"Time taken for analytics on subset: {elapsed_time_subset_analytics} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONVENTIONAL DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to load data: 0.1011967658996582 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "start_time = time.time()\n",
    "data = pd.read_csv('PRSA_data_2010.1.1-2014.12.31.csv')\n",
    "end_time = time.time()\n",
    "elapsed_time_loading = end_time - start_time\n",
    "print(f\"Time taken to load data: {elapsed_time_loading} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum and Maximum PM2.5 values:\n",
      "min      0.0\n",
      "max    994.0\n",
      "Name: pm2.5, dtype: float64\n",
      "\n",
      "Cleaned DataFrame (NA values removed):\n",
      "          No  year  month  day  hour  pm2.5  DEWP  TEMP    PRES cbwd     Iws  \\\n",
      "24        25  2010      1    2     0  129.0   -16  -4.0  1020.0   SE    1.79   \n",
      "25        26  2010      1    2     1  148.0   -15  -4.0  1020.0   SE    2.68   \n",
      "26        27  2010      1    2     2  159.0   -11  -5.0  1021.0   SE    3.57   \n",
      "27        28  2010      1    2     3  181.0    -7  -5.0  1022.0   SE    5.36   \n",
      "28        29  2010      1    2     4  138.0    -7  -5.0  1022.0   SE    6.25   \n",
      "...      ...   ...    ...  ...   ...    ...   ...   ...     ...  ...     ...   \n",
      "43819  43820  2014     12   31    19    8.0   -23  -2.0  1034.0   NW  231.97   \n",
      "43820  43821  2014     12   31    20   10.0   -22  -3.0  1034.0   NW  237.78   \n",
      "43821  43822  2014     12   31    21   10.0   -22  -3.0  1034.0   NW  242.70   \n",
      "43822  43823  2014     12   31    22    8.0   -22  -4.0  1034.0   NW  246.72   \n",
      "43823  43824  2014     12   31    23   12.0   -21  -3.0  1034.0   NW  249.85   \n",
      "\n",
      "       Is  Ir  \n",
      "24      0   0  \n",
      "25      0   0  \n",
      "26      0   0  \n",
      "27      1   0  \n",
      "28      2   0  \n",
      "...    ..  ..  \n",
      "43819   0   0  \n",
      "43820   0   0  \n",
      "43821   0   0  \n",
      "43822   0   0  \n",
      "43823   0   0  \n",
      "\n",
      "[41757 rows x 13 columns]\n",
      "Time taken for operations: 0.02016448974609375 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Calculate min and max of 'pm2.5'\n",
    "min_max_pm25 = data['pm2.5'].agg(['min', 'max'])\n",
    "print(\"Minimum and Maximum PM2.5 values:\")\n",
    "print(min_max_pm25)\n",
    "\n",
    "# Filter 'NA' values in 'pm2.5'\n",
    "data_cleaned = data[data['pm2.5'].notnull()]\n",
    "print(\"\\nCleaned DataFrame (NA values removed):\")\n",
    "print(data_cleaned)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken for operations: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with timestamp column:\n",
      "          No  year  month  day  hour  pm2.5  DEWP  TEMP    PRES cbwd     Iws  \\\n",
      "24        25  2010      1    2     0  129.0   -16  -4.0  1020.0   SE    1.79   \n",
      "25        26  2010      1    2     1  148.0   -15  -4.0  1020.0   SE    2.68   \n",
      "26        27  2010      1    2     2  159.0   -11  -5.0  1021.0   SE    3.57   \n",
      "27        28  2010      1    2     3  181.0    -7  -5.0  1022.0   SE    5.36   \n",
      "28        29  2010      1    2     4  138.0    -7  -5.0  1022.0   SE    6.25   \n",
      "...      ...   ...    ...  ...   ...    ...   ...   ...     ...  ...     ...   \n",
      "43819  43820  2014     12   31    19    8.0   -23  -2.0  1034.0   NW  231.97   \n",
      "43820  43821  2014     12   31    20   10.0   -22  -3.0  1034.0   NW  237.78   \n",
      "43821  43822  2014     12   31    21   10.0   -22  -3.0  1034.0   NW  242.70   \n",
      "43822  43823  2014     12   31    22    8.0   -22  -4.0  1034.0   NW  246.72   \n",
      "43823  43824  2014     12   31    23   12.0   -21  -3.0  1034.0   NW  249.85   \n",
      "\n",
      "       Is  Ir                timestamp  \n",
      "24      0   0  2010-01-02 00:00:00:000  \n",
      "25      0   0  2010-01-02 01:00:00:000  \n",
      "26      0   0  2010-01-02 02:00:00:000  \n",
      "27      1   0  2010-01-02 03:00:00:000  \n",
      "28      2   0  2010-01-02 04:00:00:000  \n",
      "...    ..  ..                      ...  \n",
      "43819   0   0  2014-12-31 19:00:00:000  \n",
      "43820   0   0  2014-12-31 20:00:00:000  \n",
      "43821   0   0  2014-12-31 21:00:00:000  \n",
      "43822   0   0  2014-12-31 22:00:00:000  \n",
      "43823   0   0  2014-12-31 23:00:00:000  \n",
      "\n",
      "[41757 rows x 14 columns]\n",
      "Time taken for timestamp operation: 0.0918436050415039 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1850/2004906131.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_cleaned['timestamp'] = (\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "data_cleaned['timestamp'] = (\n",
    "    data_cleaned['year'].astype(str) + '-' +\n",
    "    data_cleaned['month'].apply(lambda x: str(x).zfill(2)) + '-' +\n",
    "    data_cleaned['day'].apply(lambda x: str(x).zfill(2)) + ' ' +\n",
    "    data_cleaned['hour'].apply(lambda x: str(x).zfill(2)) + ':00:00:000'\n",
    ")\n",
    "print(\"DataFrame with timestamp column:\")\n",
    "print(data_cleaned)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken for timestamp operation: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated DataFrame:\n",
      "                     timestamp  pm2.5\n",
      "0      2010-01-02 00:00:00:000  129.0\n",
      "1      2010-01-02 01:00:00:000  148.0\n",
      "2      2010-01-02 02:00:00:000  159.0\n",
      "3      2010-01-02 03:00:00:000  181.0\n",
      "4      2010-01-02 04:00:00:000  138.0\n",
      "...                        ...    ...\n",
      "41752  2014-12-31 19:00:00:000    8.0\n",
      "41753  2014-12-31 20:00:00:000   10.0\n",
      "41754  2014-12-31 21:00:00:000   10.0\n",
      "41755  2014-12-31 22:00:00:000    8.0\n",
      "41756  2014-12-31 23:00:00:000   12.0\n",
      "\n",
      "[41757 rows x 2 columns]\n",
      "Time taken for aggregation operation: 0.023965835571289062 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1850/2352255601.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_cleaned['pm2.5'] = pd.to_numeric(data_cleaned['pm2.5'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "data_cleaned['pm2.5'] = pd.to_numeric(data_cleaned['pm2.5'], errors='coerce')\n",
    "aggregated_data = data_cleaned.groupby('timestamp')['pm2.5'].mean().reset_index()\n",
    "print(\"Aggregated DataFrame:\")\n",
    "print(aggregated_data)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken for aggregation operation: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum PM2.5 value on subset: 824.0\n",
      "Time taken for analytics on subset: 0.00028228759765625 seconds\n"
     ]
    }
   ],
   "source": [
    "subset_data = data.sample(frac=0.1, random_state=42)\n",
    "\n",
    "start_time_subset_analytics = time.time()\n",
    "max_pm25_subset = subset_data['pm2.5'].max()\n",
    "end_time_subset_analytics = time.time()\n",
    "elapsed_time_subset_analytics = end_time_subset_analytics - start_time_subset_analytics\n",
    "\n",
    "print(f\"Maximum PM2.5 value on subset: {max_pm25_subset}\")\n",
    "print(f\"Time taken for analytics on subset: {elapsed_time_subset_analytics} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum PM2.5 value on entire dataset: 994.0\n",
      "Time taken for analytics on entire dataset: 0.00044083595275878906 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time_full_analytics = time.time()\n",
    "max_pm25_full = data['pm2.5'].max()\n",
    "end_time_full_analytics = time.time()\n",
    "elapsed_time_full_analytics = end_time_full_analytics - start_time_full_analytics\n",
    "\n",
    "print(f\"Maximum PM2.5 value on entire dataset: {max_pm25_full}\")\n",
    "print(f\"Time taken for analytics on entire dataset: {elapsed_time_full_analytics} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
